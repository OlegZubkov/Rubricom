{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK data that must be downloaded only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = keras.models.load_model('.\\Model_full_extended\\Model_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatiation and tokenization of comments using NLTK library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_sent(df):\n",
    "    '''\n",
    "    The function takes dataframe with cleaned data and return Series with comments prepared for model.\n",
    "    Comments are lemmatized and tokenized.\n",
    "    '''\n",
    "    wn_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text_for_sen = []\n",
    "    \n",
    "    for comment in df['comment']:\n",
    "        lemmatized_text_for_sen.append(' '.join([wn_lemmatizer.lemmatize(word) for word in comment.split()]))\n",
    "    \n",
    "    for i in range(len(lemmatized_text_for_sen)):\n",
    "        lemmatized_text_for_sen[i] = word_tokenize(lemmatized_text_for_sen[i])\n",
    "    clean_tokenized_comment = [] \n",
    "    \n",
    "    for i, element in enumerate(lemmatized_text_for_sen):\n",
    "        clean_tokenized_comment.append(' '.join([word for word in element]))    \n",
    "    \n",
    "    return pd.Series(clean_tokenized_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating dataframe with predicted sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_calculation(df, series, model):\n",
    "    '''\n",
    "    The function returns origianl df with following columns added:\n",
    "    Comment_for_sen - preprocessed comment\n",
    "    Original_sent - original sentiment calculated as Positive in case of prod_eval >= 4 and Negative in other cases\n",
    "    Pos_prob - probability of positive sentiment according to model\n",
    "    Predicted_sent - predicted sentiment as Positive in case of pos_prob >= 0.6, Negative in case of pos_prob <= 0.4 and Neutral in other cases\n",
    "    '''\n",
    "    \n",
    "    df['Comment_for_sen'] = series\n",
    "    df['Original_sent'] = np.where(df['prod_eval'] >= 4, 'Positive', 'Negative')\n",
    "    sen_pred = model.predict(df['Comment_for_sen'])\n",
    "    df['Pos_prob'] = sen_pred\n",
    "    df['Predicted_sent'] = np.where(df['Pos_prob'] >= 0.6, 'Positive', np.where(df['Pos_prob'] <= 0.4, 'Negative', 'Neutral'))\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = sentiment_calculation(\n",
    "    df, \n",
    "    preprocessing_for_sent(df), \n",
    "    sentiment_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>Original_sent</th>\n",
       "      <th>Predicted_sent</th>\n",
       "      <th>Pos_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –ø–ª–∞–Ω–∏—Ç–∞—Ä–Ω—ã–π –º–∏–∫—Å–µ—Ä, –Ω–µ —à—É–º–Ω—ã–π,–º–æ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–°–ø–∞—Å–∏–±–æ –æ–≥—Ä–æ–º–Ω–æ–µ, –≤—Å–µ –ø—Ä–∏—à–ª–æ –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.909823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–¢–æ–≤–∞—Ä –ø–æ–ª—É—á–∏–ª–∞ 11.05. –ü–æ–ø—Ä–æ–±–æ–≤–∞–ª–∞ –≤—á–µ—Ä–∞ —Å–¥–µ–ª–∞—Ç...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.986011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ú–æ—â–Ω–æ—Å—Ç—å —á—É–≤—Å—Ç–≤—É–µ—Ç—Å—è, –≤ —Ä–∞–±–æ—Ç–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.997701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ü—Ä–æ—Å—Ç–æ –±–æ–º–±–∞! üí£–Ø –º–µ—á—Ç–∞–ª–∞ –æ –Ω–µ–º! –ö—É–ø–∏–ª–∞ –∑–∞ 6029...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—É–ø–µ—Ä. –ù–µ–º–æ–≥—É –Ω–∞—Ä–∞–¥–æ–≤–∞—Ç—å—Å—è –µ–º—É. –†–∞–±...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.988223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>18.07.2019 –ø—Ä–∏–±—ã–ª –¥–∞–Ω–Ω—ã–π –∞–≥—Ä–µ–≥–∞—Ç –≤ –Ω–∞—à –¥–æ–º, –∂–µ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>–ú–∏–∫—Å–µ—Ä –ø—Ä–æ—Å—Ç–æ –±–æ–º–±–∞! –ü—Ä–∏—à—ë–ª –≤ –¥–≤–æ–π–Ω–æ–π —É–ø–∞–∫–æ–≤–∫–µ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.999532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>–í—á–µ—Ä–∞ –ø–æ–ª—É—á–∏–ª–∞ –º–∏–∫—Å–µ—Ä,–º—É–∂ –ø–æ–¥–∞—Ä–∏–ª –Ω–∞ 30 –ª–µ—Ç–∏–µ ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.992505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>–ü–æ–ª—É—á–∏–ª–∏ –º–∏–∫—Å–µ—Ä. –ú–∏–∫—Å–µ—Ä –Ω–æ–≤—ã–π, –∫–æ—Ä–æ–±–∫–∞ –Ω–µ –º—è—Ç–∞...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.989605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>703 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment Original_sent  \\\n",
       "0    –ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π –ø–ª–∞–Ω–∏—Ç–∞—Ä–Ω—ã–π –º–∏–∫—Å–µ—Ä, –Ω–µ —à—É–º–Ω—ã–π,–º–æ...      Positive   \n",
       "1    –°–ø–∞—Å–∏–±–æ –æ–≥—Ä–æ–º–Ω–æ–µ, –≤—Å–µ –ø—Ä–∏—à–ª–æ –≤ –æ—Ç–ª–∏—á–Ω–æ–º —Å–æ—Å—Ç–æ—è...      Positive   \n",
       "2    –¢–æ–≤–∞—Ä –ø–æ–ª—É—á–∏–ª–∞ 11.05. –ü–æ–ø—Ä–æ–±–æ–≤–∞–ª–∞ –≤—á–µ—Ä–∞ —Å–¥–µ–ª–∞—Ç...      Positive   \n",
       "3    –ú–æ—â–Ω–æ—Å—Ç—å —á—É–≤—Å—Ç–≤—É–µ—Ç—Å—è, –≤ —Ä–∞–±–æ—Ç–µ –ø–æ–∫–∞ –Ω–µ –ø—Ä–æ–±–æ–≤–∞...      Positive   \n",
       "4    –ü—Ä–æ—Å—Ç–æ –±–æ–º–±–∞! üí£–Ø –º–µ—á—Ç–∞–ª–∞ –æ –Ω–µ–º! –ö—É–ø–∏–ª–∞ –∑–∞ 6029...      Positive   \n",
       "..                                                 ...           ...   \n",
       "698  –≠—Ç–æ –ø—Ä–æ—Å—Ç–æ —Å—É–ø–µ—Ä. –ù–µ–º–æ–≥—É –Ω–∞—Ä–∞–¥–æ–≤–∞—Ç—å—Å—è –µ–º—É. –†–∞–±...      Positive   \n",
       "699  18.07.2019 –ø—Ä–∏–±—ã–ª –¥–∞–Ω–Ω—ã–π –∞–≥—Ä–µ–≥–∞—Ç –≤ –Ω–∞—à –¥–æ–º, –∂–µ...      Positive   \n",
       "700  –ú–∏–∫—Å–µ—Ä –ø—Ä–æ—Å—Ç–æ –±–æ–º–±–∞! –ü—Ä–∏—à—ë–ª –≤ –¥–≤–æ–π–Ω–æ–π —É–ø–∞–∫–æ–≤–∫–µ...      Positive   \n",
       "701  –í—á–µ—Ä–∞ –ø–æ–ª—É—á–∏–ª–∞ –º–∏–∫—Å–µ—Ä,–º—É–∂ –ø–æ–¥–∞—Ä–∏–ª –Ω–∞ 30 –ª–µ—Ç–∏–µ ...      Positive   \n",
       "702  –ü–æ–ª—É—á–∏–ª–∏ –º–∏–∫—Å–µ—Ä. –ú–∏–∫—Å–µ—Ä –Ω–æ–≤—ã–π, –∫–æ—Ä–æ–±–∫–∞ –Ω–µ –º—è—Ç–∞...      Positive   \n",
       "\n",
       "    Predicted_sent  Pos_prob  \n",
       "0         Positive  0.999524  \n",
       "1         Positive  0.909823  \n",
       "2         Positive  0.986011  \n",
       "3         Positive  0.997701  \n",
       "4         Positive  0.999577  \n",
       "..             ...       ...  \n",
       "698       Positive  0.988223  \n",
       "699       Positive  0.999081  \n",
       "700       Positive  0.999532  \n",
       "701       Positive  0.992505  \n",
       "702       Positive  0.989605  \n",
       "\n",
       "[703 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['comment', 'Original_sent', 'Predicted_sent', 'Pos_prob']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe with predicted sentiments saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('./df_with_sentiments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
